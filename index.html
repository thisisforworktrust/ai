<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lite Math AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { background-color: #fafafa; color: #333; font-family: sans-serif; }
        #chat-box { 
            height: 300px; 
            overflow-y: auto; 
            border: 2px solid #ddd;
            background: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
        }
        .answer { color: #008000; font-weight: bold; margin-top: 10px; border-top: 1px dashed #ccc; padding-top: 10px;}
    </style>
</head>
<body class="p-6 max-w-xl mx-auto">

    <h1 class="text-2xl font-bold mb-2">Lite Math AI</h1>
    <p class="text-sm text-gray-500 mb-6">Using 'LaMini-77M' (Very small, won't crash)</p>

    <div id="chat-box">
        <div class="text-gray-400">Ready. Type a math problem...</div>
    </div>

    <div class="flex gap-2">
        <input type="text" id="user-input" placeholder="e.g. 25 * 4" disabled
            class="flex-1 border border-gray-400 rounded p-2">
        <button id="send-btn" disabled
            class="bg-black text-white px-6 py-2 rounded font-bold">
            Solve
        </button>
    </div>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.16.0';

        // 1. SETTINGS TO PREVENT CRASHES
        env.allowLocalModels = false; 
        env.useBrowserCache = true;
        
        // We do NOT use 'webgpu' here to ensure stability on old devices
        
        const chatBox = document.getElementById('chat-box');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        let generator;

        async function init() {
            try {
                chatBox.innerHTML = "<div class='text-blue-600'>Downloading Tiny Model (Only 200MB)...</div>";
                
                // SWITCHING TO TINY MODEL (77M Params)
                generator = await pipeline('text2text-generation', 'Xenova/LaMini-Flan-T5-77M', {
                    quantized: true
                });

                chatBox.innerHTML = "<div class='text-green-600'>Model Loaded! Safe to use.</div>";
                userInput.disabled = false;
                sendBtn.disabled = false;
                userInput.focus();
            } catch (e) {
                chatBox.innerHTML = `<div class="text-red-600">Error: ${e.message}</div>`;
            }
        }

        async function solve() {
            const text = userInput.value.trim();
            if(!text) return;
            
            userInput.value = '';
            userInput.disabled = true;
            chatBox.innerHTML = `<div><strong>Q:</strong> ${text}</div><div class="text-gray-400">Calculating...</div>`;

            try {
                // T5 models work best when you tell them exactly what to do
                const prompt = `Solve this math problem: ${text}`;

                const output = await generator(prompt, {
                    max_new_tokens: 100,
                    temperature: 0.1, // Strict math mode
                    do_sample: false
                });

                const answer = output[0].generated_text;
                
                chatBox.innerHTML = `
                    <div><strong>Q:</strong> ${text}</div>
                    <div class="answer">A: ${answer}</div>
                `;

            } catch (e) {
                chatBox.innerHTML += `<div class="text-red-500">Error.</div>`;
            }

            userInput.disabled = false;
            userInput.focus();
        }

        sendBtn.addEventListener('click', solve);
        userInput.addEventListener('keypress', (e) => { if(e.key==='Enter') solve() });

        init();
    </script>
</body>
</html>
