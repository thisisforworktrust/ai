<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Free Browser AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        #chat-box { height: 60vh; overflow-y: auto; }
        .loading-spinner { border-top-color: #3498db; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-gray-900 text-white font-sans p-4">

    <div class="max-w-2xl mx-auto bg-gray-800 rounded-lg shadow-xl p-6">
        <h1 class="text-2xl font-bold mb-2 text-blue-400">Local Browser AI</h1>
        <p class="text-sm text-gray-400 mb-4">The first load will take ~30 seconds to download the model. After that, it's instant and works offline!</p>
        
        <div id="status" class="mb-4 text-xs font-mono text-yellow-500">Loading AI Engine...</div>

        <div id="chat-box" class="space-y-4 mb-4 border-t border-b border-gray-700 py-4">
            <div class="text-gray-500 italic">Waiting for AI to initialize...</div>
        </div>

        <div class="flex gap-2">
            <input type="text" id="user-input" placeholder="Type something..." 
                class="flex-1 bg-gray-700 rounded p-2 focus:outline-none focus:ring-2 focus:ring-blue-500" disabled>
            <button id="send-btn" class="bg-blue-600 hover:bg-blue-700 px-4 py-2 rounded font-bold disabled:opacity-50" disabled>Send</button>
        </div>
    </div>

    <script type="module">
        import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.5.1';

        const status = document.getElementById('status');
        const chatBox = document.getElementById('chat-box');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');

        let generator;

        // Initialize the AI
        async function init() {
            try {
                // Using SmolLM-135M: it's only ~250MB and runs well in browsers
                generator = await pipeline('text-generation', 'onnx-community/SmolLM-135M-Instruct', {
                    device: 'webgpu', // Try to use the GPU for speed
                    dtype: 'q4',    // Compressed version to save space
                    progress_callback: (p) => {
                        if (p.status === 'progress') {
                            status.innerText = `Downloading model: ${p.progress.toFixed(1)}%`;
                        }
                    }
                });
                
                status.innerText = "âœ… AI Ready! (Running on your Hardware)";
                status.classList.replace('text-yellow-500', 'text-green-500');
                userInput.disabled = false;
                sendBtn.disabled = false;
                chatBox.innerHTML = '<div class="text-blue-300">AI: Hello! Ask me anything. I am running entirely in your browser.</div>';
            } catch (err) {
                status.innerText = "Error: Use a browser that supports WebGPU (like Chrome/Edge).";
                console.error(err);
            }
        }

        async function handleChat() {
            const text = userInput.value;
            if (!text) return;

            // Display User Message
            chatBox.innerHTML += `<div class="text-right"><span class="bg-blue-900 p-2 rounded-lg inline-block">You: ${text}</span></div>`;
            userInput.value = '';
            
            // Generate AI Response
            const output = await generator(text, { 
                max_new_tokens: 100,
                temperature: 0.7,
                do_sample: true 
            });

            const aiResponse = output[0].generated_text.replace(text, '').trim();
            chatBox.innerHTML += `<div class="text-left text-blue-300">AI: ${aiResponse}</div>`;
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        sendBtn.addEventListener('click', handleChat);
        userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') handleChat(); });

        init();
    </script>
</body>
</html>
