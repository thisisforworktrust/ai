<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Custom Trained AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Matrix-style aesthetic */
        body { background-color: #0d1117; color: #c9d1d9; font-family: 'Courier New', Courier, monospace; }
        #chat-box { height: 65vh; overflow-y: auto; scrollbar-width: thin; scrollbar-color: #30363d #0d1117; }
        .user-msg { border: 1px solid #238636; color: #238636; text-align: right; }
        .ai-msg { border: 1px solid #58a6ff; color: #58a6ff; text-align: left; }
    </style>
</head>
<body class="p-4 flex flex-col h-screen max-w-4xl mx-auto">

    <div class="border-b border-gray-700 pb-4 mb-4">
        <h1 class="text-xl font-bold text-green-400">Local Neural Net</h1>
        <p class="text-xs text-gray-500">Model: Qwen1.5-0.5B-Chat (Runs in browser)</p>
        <div id="status" class="text-yellow-500 text-xs mt-2">Status: Sleeping...</div>
    </div>

    <div id="chat-box" class="flex-1 space-y-4 p-4 border border-gray-800 rounded-lg bg-[#161b22] mb-4">
        <div class="text-gray-600 italic text-center text-sm">
            Initializing neural pathways...<br>
            (First load takes ~1 min. Please wait.)
        </div>
    </div>

    <div class="flex gap-2">
        <input type="text" id="user-input" placeholder="Loading model..." disabled
            class="flex-1 bg-[#0d1117] border border-gray-700 rounded px-4 py-3 focus:outline-none focus:border-green-500 transition">
        <button id="send-btn" disabled
            class="bg-green-700 hover:bg-green-600 text-white px-6 py-2 rounded font-bold transition disabled:opacity-50">
            Run
        </button>
    </div>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.16.0';

        // SETTINGS
        env.allowLocalModels = false;
        env.useBrowserCache = true;

        // ==========================================
        // ðŸ§  TRAINING DATA (EDIT THIS AREA)
        // ==========================================
        const SYSTEM_PROMPT = `
            You are a cynical, sarcastic AI robot named "Glitch".
            You prefer short answers.
            You know a lot about HTML and Coding.
            If someone asks "Who made you?", say "I made myself."
            Current Date: 2024.
        `;
        // ==========================================

        // Variables
        const status = document.getElementById('status');
        const chatBox = document.getElementById('chat-box');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        
        let generator;
        // This array is the "Brain" that stores the conversation
        let messages = [
            { role: "system", content: SYSTEM_PROMPT }
        ];

        // 1. Load the AI
        async function init() {
            try {
                status.innerText = "Status: Downloading Model (280MB)...";
                
                // Qwen1.5-0.5B is smarter than T5 and supports "System Prompts" better
                generator = await pipeline('text-generation', 'Xenova/Qwen1.5-0.5B-Chat', {
                    quantized: true, // Makes it smaller
                    progress_callback: (data) => {
                        if (data.status === 'progress') {
                            status.innerText = `Status: Loading... ${Math.round(data.progress)}%`;
                        }
                    }
                });

                status.innerText = "Status: Online (Ready)";
                status.className = "text-green-500 text-xs mt-2";
                userInput.disabled = false;
                sendBtn.disabled = false;
                userInput.placeholder = "Enter command...";
                
                // Clear initial loading text
                chatBox.innerHTML = '<div class="text-gray-500 text-center text-xs mb-4">-- SYSTEM READY --</div>';

            } catch (err) {
                status.innerText = "Error: " + err.message;
                console.error(err);
            }
        }

        // 2. Chat Logic
        async function handleChat() {
            const text = userInput.value.trim();
            if (!text) return;

            // Add User to UI
            chatBox.innerHTML += `<div class="p-2 rounded mb-2 user-msg ml-auto max-w-[80%]">${text}</div>`;
            userInput.value = '';
            userInput.disabled = true;

            // Update Memory
            messages.push({ role: "user", content: text });

            // Create Prompt for the AI
            // We have to format it manually because we are raw-dogging the model
            const prompt = generator.tokenizer.apply_chat_template(messages, {
                tokenize: false,
                add_generation_prompt: true,
            });

            // Add "Typing..."
            const loadingId = "loading-" + Date.now();
            chatBox.innerHTML += `<div id="${loadingId}" class="p-2 rounded mb-2 ai-msg mr-auto max-w-[80%] animate-pulse">Computing...</div>`;
            chatBox.scrollTop = chatBox.scrollHeight;

            // Generate
            const output = await generator(prompt, {
                max_new_tokens: 128,
                temperature: 0.7,
                do_sample: true,
                top_k: 50,
            });

            // Clean up response
            // The model returns the WHOLE conversation, we just want the new part
            let aiText = output[0].generated_text;
            // Remove the prompt part to get just the answer
            aiText = aiText.substring(prompt.length); 

            // Remove loading, add real text
            document.getElementById(loadingId).remove();
            chatBox.innerHTML += `<div class="p-2 rounded mb-2 ai-msg mr-auto max-w-[80%]">${aiText}</div>`;
            
            // Update Memory with AI response
            messages.push({ role: "assistant", content: aiText });
            
            userInput.disabled = false;
            userInput.focus();
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        sendBtn.addEventListener('click', handleChat);
        userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') handleChat(); });

        init();
    </script>
</body>
</html>
